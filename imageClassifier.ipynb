{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "googlenetVersion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Kf44feeoPw",
        "colab_type": "text"
      },
      "source": [
        "#Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haTmLd68QPQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from collections import namedtuple\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qogRMJ-yeszc",
        "colab_type": "text"
      },
      "source": [
        "# Downloading, Loading and Normalising CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zb2cY7nQaA5",
        "colab_type": "code",
        "outputId": "3878a816-a9b4-4e40-def0-e9b145d7e5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=50,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                       train=False,\n",
        "                                       download=True, \n",
        "                                       transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                         batch_size=50,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 73756926.32it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGy6X91F2VV4",
        "colab_type": "text"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1ha1bls6iFI",
        "colab_type": "code",
        "outputId": "bab0b3c4-a827-4768-e17f-7ff81c1bf729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "is_cuda = torch.cuda.is_available()\n",
        "is_cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U4uLc4S2bkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
        "    for e in range(epoch):\n",
        "      if is_cuda:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "        model = model.cuda()\n",
        "      if phase == 'training':\n",
        "          model.train()\n",
        "      if phase == 'validation':\n",
        "          model.eval()\n",
        "          # volatile=True\n",
        "      running_loss = 0.0\n",
        "      running_correct = 0\n",
        "      for batch_idx , (data,target) in enumerate(data_loader):\n",
        "          if is_cuda:\n",
        "              data,target = data.cuda(),target.cuda()\n",
        "          # data , target = Variable(data,volatile),Variable(target)\n",
        "          if phase == 'training':\n",
        "              optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = criterion(output,target)\n",
        "          \n",
        "          running_loss += F.cross_entropy(output,target,size_average=False).data\n",
        "          preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "          running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "          if phase == 'training':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "      \n",
        "      loss = running_loss/len(data_loader.dataset)\n",
        "      accuracy = 100. * running_correct.item()/len(data_loader.dataset)\n",
        "      \n",
        "      print(f'epoch : {e+1} :{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
        "    return loss,accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXZ8VGpz0JrI",
        "colab_type": "text"
      },
      "source": [
        "# Creating Inception V1 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4DK0BHomCy6",
        "colab_type": "text"
      },
      "source": [
        "## define Inception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IduiQIfWl_wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n",
        "            nn.BatchNorm2d(n1x1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.b2 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n3x3red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n3x3),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.b3 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n",
        "            nn.BatchNorm2d(n5x5red),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n5x5),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 3x3 pool -> 1x1 conv branch\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_planes),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1,y2,y3,y4], 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv6xT3o0mNIy",
        "colab_type": "text"
      },
      "source": [
        "## Define GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRnOGzUixKAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''GoogLeNet with PyTorch.'''\n",
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.pre_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
        "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
        "        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
        "        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
        "        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
        "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "        self.linear = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pre_layers(x)\n",
        "        out = self.a3(out)\n",
        "        out = self.b3(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a4(out)\n",
        "        out = self.b4(out)\n",
        "        out = self.c4(out)\n",
        "        out = self.d4(out)\n",
        "        out = self.e4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.a5(out)\n",
        "        out = self.b5(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "net = GoogLeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGnSy9xPfnbL",
        "colab_type": "text"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da2f35ec-f510-48d0-f28a-4481cab9b68d",
        "id": "k77WUKW_XpOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "fit(10,net,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch : 1 :training loss is   1.3 and training accuracy is 25780/50000     51.56\n",
            "epoch : 2 :training loss is  0.85 and training accuracy is 35001/50000      70.0\n",
            "epoch : 3 :training loss is  0.64 and training accuracy is 38971/50000     77.94\n",
            "epoch : 4 :training loss is  0.49 and training accuracy is 41424/50000     82.85\n",
            "epoch : 5 :training loss is  0.39 and training accuracy is 43239/50000     86.48\n",
            "epoch : 6 :training loss is  0.31 and training accuracy is 44723/50000     89.45\n",
            "epoch : 7 :training loss is  0.24 and training accuracy is 45852/50000      91.7\n",
            "epoch : 8 :training loss is  0.19 and training accuracy is 46786/50000     93.57\n",
            "epoch : 9 :training loss is  0.15 and training accuracy is 47487/50000     94.97\n",
            "epoch : 10 :training loss is  0.11 and training accuracy is 48195/50000     96.39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1108, device='cuda:0'), 96.39)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU4_wXdGDwPR",
        "colab_type": "text"
      },
      "source": [
        "# Testing network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpWInz5e61iJ",
        "colab_type": "code",
        "outputId": "80466858-13ec-425b-cf4e-51a66f82f95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_correct = 0\n",
        "total_images = 0\n",
        "confusion_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels =  images.cuda(), labels.cuda()\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_images += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        for i, l in enumerate(labels):\n",
        "            confusion_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "model_accuracy = total_correct / total_images * 100\n",
        "print('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy on 10000 test images: 83.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gynp9hx6_lf",
        "colab_type": "code",
        "outputId": "66492f71-b192-4260-dc44-094c73dabdfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print('{0:10s} - Accuarcy'.format('Category'))\n",
        "for i, r in enumerate(confusion_matrix):\n",
        "    print('{0:10s} - {1:.1f}'.format(classes[i], r[i]/np.sum(r)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category   - Accuarcy\n",
            "plane      - 84.8\n",
            "car        - 93.6\n",
            "bird       - 77.8\n",
            "cat        - 73.4\n",
            "deer       - 80.5\n",
            "dog        - 76.5\n",
            "frog       - 81.2\n",
            "horse      - 88.4\n",
            "ship       - 91.6\n",
            "truck      - 87.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfqRPClOEGIW",
        "colab_type": "text"
      },
      "source": [
        "Finally, let us visualise the confusion matrix to determine common misclassifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCgUZ0S57cpN",
        "colab_type": "code",
        "outputId": "aa16aa60-d630-4513-8c55-29ed6ec5c9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
        "ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n",
        "plt.ylabel('Actual Category')\n",
        "plt.yticks(range(10), classes)\n",
        "plt.xlabel('Predicted Category')\n",
        "plt.xticks(range(10), classes)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFzCAYAAAA0dtAgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYdGXJKkjLPqSJHXE/w+za3iQIMCqPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznwQqTfENUH",
        "colab_type": "text"
      },
      "source": [
        "From the above visualisation we can see that the best accuracy was achieved on the **`car`** and **`ship`** categories, darkest shades present on the main diagonal. The **`truck`** category was most frequently confused with the **`car`** category. This is understandable, since they are both vehicles and have some visual similarities. **`Planes`** were also commonly confused with **`bird`** and **`ship`**. This could have something to do with a common background texture and colour, blue for both sky and sea. **`cat`** were also commonly confused with **`dog`** and **`frog`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLXlDJmaFKrx",
        "colab_type": "text"
      },
      "source": [
        "To understand precisely which categories were most commonly confused, we can print the absolute and relative values of the confusion matrix, as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrTQRqF7z9M",
        "colab_type": "code",
        "outputId": "c2d68453-a93a-4012-fa1e-3513b24f4842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "print('actual/pred'.ljust(16), end='')\n",
        "for i,c in enumerate(classes):\n",
        "    print(c.ljust(10), end='')\n",
        "print()\n",
        "for i,r in enumerate(confusion_matrix):\n",
        "    print(classes[i].ljust(16), end='')\n",
        "    for idx, p in enumerate(r):\n",
        "        print(str(p).ljust(10), end='')\n",
        "    print()\n",
        "    \n",
        "    r = r/np.sum(r)\n",
        "    print(''.ljust(16), end='')\n",
        "    for idx, p in enumerate(r):\n",
        "        print(str(p).ljust(10), end='')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual/pred     plane     car       bird      cat       deer      dog       frog      horse     ship      truck     \n",
            "plane           848       20        18        19        14        3         5         7         50        16        \n",
            "                0.848     0.02      0.018     0.019     0.014     0.003     0.005     0.007     0.05      0.016     \n",
            "car             11        936       0         3         0         2         3         2         11        32        \n",
            "                0.011     0.936     0.0       0.003     0.0       0.002     0.003     0.002     0.011     0.032     \n",
            "bird            45        7         778       40        43        31        15        23        12        6         \n",
            "                0.045     0.007     0.778     0.04      0.043     0.031     0.015     0.023     0.012     0.006     \n",
            "cat             11        8         41        734       39        110       19        23        9         6         \n",
            "                0.011     0.008     0.041     0.734     0.039     0.11      0.019     0.023     0.009     0.006     \n",
            "deer            18        2         32        61        805       17        12        48        5         0         \n",
            "                0.018     0.002     0.032     0.061     0.805     0.017     0.012     0.048     0.005     0.0       \n",
            "dog             1         1         34        120       30        765       8         35        1         5         \n",
            "                0.001     0.001     0.034     0.12      0.03      0.765     0.008     0.035     0.001     0.005     \n",
            "frog            8         4         43        80        26        18        812       4         3         2         \n",
            "                0.008     0.004     0.043     0.08      0.026     0.018     0.812     0.004     0.003     0.002     \n",
            "horse           10        7         13        29        21        28        3         884       1         4         \n",
            "                0.01      0.007     0.013     0.029     0.021     0.028     0.003     0.884     0.001     0.004     \n",
            "ship            30        17        3         6         2         3         5         2         916       16        \n",
            "                0.03      0.017     0.003     0.006     0.002     0.003     0.005     0.002     0.916     0.016     \n",
            "truck           16        71        3         11        2         3         2         3         12        877       \n",
            "                0.016     0.071     0.003     0.011     0.002     0.003     0.002     0.003     0.012     0.877     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}